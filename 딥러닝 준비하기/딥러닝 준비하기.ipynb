{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.9 64-bit (conda)",
   "metadata": {
    "interpreter": {
     "hash": "97ae724bfa85b9b34df7982b8bb8c7216f435b92902d749e4263f71162bea840"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "> # Convolutional Neural Network"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "input - repeat(Convolution - Subsampling) - Fully Connected(Dens Layer) - output\n",
    "\n",
    "- Local Invariance: 국소적으로 크게 차이가 나지 않음. 같은 filter가 한 이미지의 전체를 돌면서 물체 위치에 대해 약간 차이가 나도 이를 미미하게 만들어줌.\n",
    "- Compositionality: CNN's hierachicality\n",
    "\n",
    "\n",
    "- (Convolutional) feature map: convolution 계층을 통해 만들어지는 결과물.\n",
    "- feature extraction\n",
    "- Zero-padding: <i>n<sub>out</sub> = (n<sub>in</sub> + 2 * n<sub>padding</sub> - n <sub>filter</sub> ) + 1</i>\n",
    "- Stride (if stride size equals the filter size, there will be overlapping)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "2.3.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "source": [
    "tf.nn.conv2d(input, filter, strides, padding, use_cudnn_on_gpu=None, name=None)\n",
    "- input.shape = \\[batch, in_height, in_width, in_channel\\]\n",
    "- filter.shape = \\[filter_height, filter_width, in_channels, out_channels\\]\n",
    "\n",
    "\n",
    "- batch: mini-batch 이용, batch size\n",
    "- in_channel: 이미지 채널 수\n",
    "- out_channel: filter의 수이자 다음 계층의 channel 수"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "> weight parameter의 수를 줄이는 게 중요"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "pooling\n",
    "\n",
    "- max pooling\n",
    "- average pooling"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "(reshape) re-ordering: fully-connected layer을 위해 한 줄로 펴기"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "*중요*\n",
    "\n",
    "- conv 하나에 640 : fully 하나에 125,440 정도\n",
    "- NN은 parameter가 많으면 별로\n",
    "- 그래서 fully-connected를 줄이고자 함."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "> # 기계학습 용어 정리\n",
    "\n",
    "- input\n",
    "- output, class, label (대체로 One-hot coding을 이용)\n",
    "- training, learning\n",
    "- (SGD, Momentum, NAG, Adagrad, Adadelta, Rmsprop) 언급만\n",
    "- dataset: Training Data, Validation Data (Cross-validation), Test Data\n",
    "\n",
    "\n",
    "- Neuron\n",
    "- Activation function: multi layer에서 비선형을 부여하는 역할, 선형 함수는 또 다른 선형 함수로 표현될 뿐.\n",
    "- sigmoid(확률), ReLU(일반적 분류 NN), thanh(음수가 필요할 때), softplus(regression에 좋은 편)\n",
    "- MLP (Multi-Layer Perceptron)\n",
    "\n",
    "\n",
    "- Epoch: 준비된 모든 데이터셋을 한 번 사용했을 떄의 단위\n",
    "- Batch size: 한 번 gradient를 계산할 때의 데이터 크기\n",
    "- Iteration\n",
    "> If we have 55,000 training data, and the batch size is 1,000. Then, we need 55 iterations to complete 1 epoch.\n",
    "\n",
    "\n",
    "Cost function\n",
    "- output과 실제값과의 차이를 어떻게 정의하냐에 따라 이것저것 많이 사용함.\n",
    "- 당연하세도 미분이 가능해야 함.\n",
    "- 강화학습의 reinforce 어쩌구 알고리즘을 통해 미분이 가능하지 않아도 가능하긴 하다고 함."
   ],
   "cell_type": "markdown",
   "metadata": {}
  }
 ]
}