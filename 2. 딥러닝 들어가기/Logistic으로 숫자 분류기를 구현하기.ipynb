{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "tensorflow",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "## Logistic으로 숫자 분류기를 구현하기\n",
    "- 왜 regression으로 쓰신 거지, classification에 가까운데"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "Cross Entropy (CE, Error, Method)\n",
    "\n",
    "- information theory에서 등장, p와 q의 분포 사이의 거리를 재고자 했음.\n",
    "- 각 분포의 도메인을 각각 곱하고 더해서 음수를 취한 거.\n",
    "- 딥러닝에선 예측과 실제 사이에서 서로 해당하는 값을 곱하고 합해서 만들어짐.\n",
    "- SoftMax를 통해서 0 ~ 1 사이의 값들로 변환한 값과 one-hot coding으로 나온 클래스를 가지고 Cross Entropy\n",
    "- 결과적으로 각 클래스에 확률에 영향을 주는 것만 건들이고(정확도를 높이고), 나머지는 관여 안 함."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "1.15.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "WARNING:tensorflow:From <ipython-input-2-24080ce578b7>:1: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From C:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\contrib\\learn\\python\\learn\\datasets\\mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From C:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\contrib\\learn\\python\\learn\\datasets\\base.py:252: _internal_retry.<locals>.wrap.<locals>.wrapped_fn (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use urllib or similar directly.\n",
      "Successfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\n",
      "WARNING:tensorflow:From C:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\contrib\\learn\\python\\learn\\datasets\\mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting data/train-images-idx3-ubyte.gz\n",
      "Successfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.\n",
      "WARNING:tensorflow:From C:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\contrib\\learn\\python\\learn\\datasets\\mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting data/train-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\contrib\\learn\\python\\learn\\datasets\\mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.one_hot on tensors.\n",
      "Successfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.\n",
      "Extracting data/t10k-images-idx3-ubyte.gz\n",
      "Successfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.\n",
      "Extracting data/t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\contrib\\learn\\python\\learn\\datasets\\mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
     ]
    }
   ],
   "source": [
    "mnist = input_data.read_data_sets(\"data/\", one_hot=True)\n",
    "trainimg = mnist.train.images\n",
    "trainlabel = mnist.train.labels\n",
    "testimg = mnist.test.images\n",
    "testlabel = mnist.test.labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.placeholder(\"float\", [None, 784])\n",
    "y = tf.placeholder(\"float\", [None, 10])\n",
    "w = tf.Variable(tf.zeros([784, 10]))\n",
    "b = tf.Variable(tf.zeros([10]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "actv = tf.nn.softmax(tf.matmul(x, w) + b)\n",
    "cost = tf.reduce_mean(-tf.reduce_sum(y * tf.log(actv), reduction_indices=1))\n",
    "# tf.nn.CrossEntropy 어쩌구\n",
    "learning_rate = 0.01\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = tf.equal(tf.argmax(actv, 1), tf.argmax(y, 1))\n",
    "# argmax는 제일 큰 숫자의 인덱스를 찾는 함수지.\n",
    "accuracy = tf.reduce_mean(tf.cast(pred, \"float\"))\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch: [0/50] \tcost: 1.177 \ttrain_acc: 0.8399999737739563 \ttest_acc: 1\n",
      "Epoch: [5/50] \tcost: 0.44 \ttrain_acc: 0.8199999928474426 \ttest_acc: 1\n",
      "Epoch: [10/50] \tcost: 0.383 \ttrain_acc: 0.9100000262260437 \ttest_acc: 1\n",
      "Epoch: [15/50] \tcost: 0.358 \ttrain_acc: 0.9399999976158142 \ttest_acc: 1\n",
      "Epoch: [20/50] \tcost: 0.341 \ttrain_acc: 0.9399999976158142 \ttest_acc: 1\n",
      "Epoch: [25/50] \tcost: 0.331 \ttrain_acc: 0.8600000143051147 \ttest_acc: 1\n",
      "Epoch: [30/50] \tcost: 0.322 \ttrain_acc: 0.949999988079071 \ttest_acc: 1\n",
      "Epoch: [35/50] \tcost: 0.316 \ttrain_acc: 0.8999999761581421 \ttest_acc: 1\n",
      "Epoch: [40/50] \tcost: 0.311 \ttrain_acc: 0.949999988079071 \ttest_acc: 1\n",
      "Epoch: [45/50] \tcost: 0.306 \ttrain_acc: 0.9300000071525574 \ttest_acc: 1\n"
     ]
    }
   ],
   "source": [
    "training_epochs = 50\n",
    "batch_size = 100\n",
    "display_step = 5\n",
    "num_batch = int(mnist.train.num_examples / batch_size)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    for epoch in range(training_epochs):\n",
    "        avg_cost = 0.0\n",
    "        batch_xs = []\n",
    "        batch_ys = []\n",
    "        for i in range(num_batch):\n",
    "            batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
    "            sess.run(optimizer, feed_dict={x: batch_xs, y: batch_ys})\n",
    "            avg_cost += sess.run(cost, feed_dict={x: batch_xs, y: batch_ys}) / num_batch\n",
    "        if epoch % display_step == 0:\n",
    "            train_acc = sess.run(accuracy, feed_dict={x: batch_xs, y: batch_ys})\n",
    "            test_acc = sess.run(accuracy, feed_dict={x: testimg, y: testlabel})\n",
    "            print(\"Epoch: [{}/{}] \\tcost: {} \\ttrain_acc: {} \\ttest_acc: {}\"\n",
    "            .format(epoch, training_epochs, avg_cost, train_acc, test_acc))"
   ]
  }
 ]
}